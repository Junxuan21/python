{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import lxml.html\n",
    "import MySQLdb as mdb\n",
    "\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_parse_wiki_snp500():\n",
    "  \n",
    "    \"\"\" \n",
    "  Download and parse the Wikipedia list of S&P500 \n",
    "  constituents using requests and libxml.\n",
    "\n",
    "  Returns a list of tuples for to add to MySQL.\n",
    "    \"\"\"\n",
    "\n",
    "    # Stores the current time, for the created_at record\n",
    "    now = datetime.datetime.utcnow()\n",
    "    # Use libxml to download the list of S&P500 companies and obtain the symbol table\n",
    "    page = lxml.html.parse('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    symbolslist = page.xpath('//table[1]/tr')[1:]\n",
    "    \n",
    "    # Obtain the symbol information for each row in the S&P500 constituent table\n",
    "    symbols = []\n",
    "\n",
    "    for symbol in symbolslist:\n",
    "        tds = symbol.getchildren()\n",
    "        sd = {'ticker': tds[0].getchildren()[0].text,\n",
    "        'name': tds[1].getchildren()[0].text,\n",
    "        'sector': tds[3].text}\n",
    "\n",
    "    # Create a tuple (for the DB format) and append to the grand list\n",
    "    symbols.append( (sd['ticker'], 'stock', sd['name'], sd['sector'], 'USD', now, now) )\n",
    "    return symbols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_snp500_symbols(symbols):\n",
    "  \"\"\"\n",
    "  Insert the S&P500 symbols into the MySQL database.\n",
    "  \"\"\"\n",
    "\n",
    "    # Connect to the MySQL instance\n",
    "    db_host = 'localhost'\n",
    "    db_user = 'sec_user'\n",
    "    db_pass = 'password'\n",
    "    db_name = 'securities_master'\n",
    "    con = mdb.connect(host=db_host, user=db_user, passwd=db_pass, db=db_name)\n",
    "    \n",
    "    # Create the insert strings\n",
    "    column_str = \"ticker, instrument, name, sector, currency, created_date, last_updated_date\"\n",
    "    insert_str = (\"%s, \" * 7)[:-2]\n",
    "    final_str = \"INSERT INTO symbol (%s) VALUES (%s)\" % (column_str, insert_str)\n",
    "    print final_str, len(symbols)\n",
    "\n",
    "    # Using the MySQL connection, carry out an INSERT INTO for every symbol\n",
    "    with con: \n",
    "        cur = con.cursor()\n",
    "        # This line avoids the MySQL MAX_PACKET_SIZE\n",
    "        # Although of course it could be set larger!\n",
    "    \n",
    "        for i in range(0, int(ceil(len(symbols) / 100.0))):\n",
    "            cur.executemany(final_str, symbols[i*100:(i+1)*100-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    symbols = obtain_parse_wiki_snp500()\n",
    "    insert_snp500_symbols(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import MySQLdb as mdb\n",
    "import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a database connection to the MySQL instance\n",
    "\n",
    "db_host = 'localhost'\n",
    "db_user = 'sec_user'\n",
    "db_pass = 'password'\n",
    "db_name = 'securities_master'\n",
    "con = mdb.connect(db_host, db_user, db_pass, db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_list_of_db_tickers():\n",
    "  \n",
    "    # Obtains a list of the ticker symbols in the database.\n",
    "    with con: \n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"SELECT id, ticker FROM symbol\")\n",
    "        data = cur.fetchall()\n",
    "        \n",
    "        return [(d[0], d[1]) for d in data]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_historic_data_yahoo(ticker,\n",
    "                      start_date=(2000,1,1),\n",
    "                      end_date=datetime.date.today().timetuple()[0:3]):\n",
    "\n",
    "    \"\"\" \n",
    "    Obtains data from Yahoo Finance returns and a list of tuples.\n",
    "    ticker: Yahoo Finance ticker symbol, e.g. \"GOOG\" for Google, Inc.\n",
    "    start_date: Start date in (YYYY, M, D) format\n",
    "    end_date: End date in (YYYY, M, D) format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct the Yahoo URL with the correct integer query parameters\n",
    "    # for start and end dates. Note that some parameters are zero-based!\n",
    "\n",
    "    yahoo_url = \"http://ichart.finance.yahoo.com/table.csv?s=%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s\" % \\\n",
    "      (ticker, start_date[1] - 1, start_date[2], start_date[0], end_date[1] - 1, end_date[2], end_date[0])\n",
    "    \n",
    "    \n",
    "    # Try connecting to Yahoo Finance and obtaining the data\n",
    "    # On failure, print an error message.\n",
    "    try:\n",
    "        yf_data = urllib.urlopen(yahoo_url).readlines()[1:] # Ignore the header\n",
    "        prices = []\n",
    "        for y in yf_data:\n",
    "            p = y.strip().split(',')\n",
    "            prices.append( (datetime.datetime.strptime(p[0], '%Y-%m-%d'),\n",
    "                            p[1], p[2], p[3], p[4], p[5], p[6]) )\n",
    "            \n",
    "    except Exception, e:\n",
    "        print (\"Could not download Yahoo data: %s\" % e)\n",
    "        \n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_daily_data_into_db(data_vendor_id, symbol_id, daily_data):\n",
    "  \"\"\"\n",
    "  Takes a list of tuples of daily data and adds it to the\n",
    "  MySQL database. Appends the vendor ID and symbol ID to the data.\n",
    "\n",
    "  daily_data: List of tuples of the OHLC data (with \n",
    "  adj_close and volume)\n",
    "  \"\"\"\n",
    "\n",
    "    # Create the time now\n",
    "    now = datetime.datetime.utcnow()\n",
    "    \n",
    "    # Amend the data to include the vendor ID and symbol ID\n",
    "    daily_data = [(data_vendor_id, symbol_id, d[0], now, now,\n",
    "               d[1], d[2], d[3], d[4], d[5], d[6]) for d in daily_data]\n",
    "    \n",
    "    # Create the insert strings\n",
    "    column_str = \"\"\"data_vendor_id, symbol_id, price_date, created_date, \n",
    "             last_updated_date, open_price, high_price, low_price, \n",
    "             close_price, volume, adj_close_price\"\"\"\n",
    "    insert_str = (\"%s, \" * 11)[:-2]\n",
    "\n",
    "    final_str = \"INSERT INTO daily_price (%s) VALUES (%s)\" % (column_str, insert_str)\n",
    "    \n",
    "    # Using the MySQL connection, carry out an INSERT INTO for every symbol\n",
    "    with con:\n",
    "        cur = con.cursor()\n",
    "        cur.executemany(final_str, daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  # Loop over the tickers and insert the daily historical\n",
    "  # data into the database\n",
    "    \n",
    "    tickers = obtain_list_of_db_tickers()\n",
    "    for t in tickers:\n",
    "        print (\"Adding data for %s\" % t[1])\n",
    "\n",
    "        yf_data = get_daily_historic_data_yahoo(t[1])\n",
    "        insert_daily_data_into_db('1', t[0], yf_data)\n",
    "        \n",
    "        try:\n",
    "            yf_data = urllib.urlopen(yahoo_url).readlines()\n",
    "        except Exception, e:\n",
    "            print (\"Could not download Yahoo data: %s\" % e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the (temporary) Python data structures to store the historical data\n",
    "\n",
    "date_list = []\n",
    "hist_data = [[] for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format and copy the raw text data into datetime objects\n",
    "# and floating point values (still in native Python lists)\n",
    "\n",
    "for day in yf_data[1:]:  # Avoid the header line in the CSV\n",
    "    headers = day.rstrip().split(',')\n",
    "    date_list.append(datetime.datetime.strptime(headers[0],'%Y-%m-%d'))\n",
    "    for i, header in enumerate(headers[1:]):\n",
    "        hist_data[i].append(float(header))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Python dictionary of the lists and then use that to\n",
    "# form a sorted Pandas DataFrame of the historical data\n",
    "\n",
    "hist_data = dict(zip(['open', 'high', 'low', 'close', 'volume', 'adj_close'], hist_data))\n",
    "pdf = pd.DataFrame(hist_data, index=pd.Index(date_list)).sort()\n",
    "\n",
    "return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annualised_sharpe(returns, N=252):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the annualised Sharpe ratio of a returns stream \n",
    "    based on a number of trading periods, N. N defaults to 252,\n",
    "    which then assumes a stream of daily returns.\n",
    "\n",
    "    The function assumes that the returns are the excess of \n",
    "    those compared to a benchmark.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sqrt(N) * returns.mean() / returns.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equity_sharpe(ticker):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the annualised Sharpe ratio based on the daily\n",
    "    returns of an equity ticker symbol listed in Yahoo Finance.\n",
    "\n",
    "    The dates have been hardcoded here for the QuantStart article \n",
    "    on Sharpe ratios.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtain the equities daily historic data for the desired time period\n",
    "    # and add to a pandas DataFrame\n",
    "    pdf = get_historic_data(ticker, start_date=(2000,1,1), end_date=(2013,5,29))\n",
    "\n",
    "    # Use the percentage change method to easily calculate daily returns\n",
    "    pdf['daily_ret'] = pdf['adj_close'].pct_change()\n",
    "\n",
    "    # Assume an average annual risk-free rate over the period of 5%\n",
    "    pdf['excess_daily_ret'] = pdf['daily_ret'] - 0.05/252\n",
    "\n",
    "    # Return the annualised Sharpe ratio based on the excess daily returns\n",
    "    return annualised_sharpe(pdf['excess_daily_ret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_neutral_sharpe(ticker, benchmark):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the annualised Sharpe ratio of a market\n",
    "    neutral long/short strategy inolving the long of 'ticker'\n",
    "    with a corresponding short of the 'benchmark'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get historic data for both a symbol/ticker and a benchmark ticker\n",
    "    # The dates have been hardcoded, but you can modify them as you see fit!\n",
    "    tick = get_historic_data(ticker, start_date=(2000,1,1), end_date=(2013,5,29))\n",
    "    bench = get_historic_data(benchmark, start_date=(2000,1,1), end_date=(2013,5,29))\n",
    "    \n",
    "    # Calculate the percentage returns on each of the time series\n",
    "    tick['daily_ret'] = tick['adj_close'].pct_change()\n",
    "    bench['daily_ret'] = bench['adj_close'].pct_change()\n",
    "    \n",
    "    # Create a new DataFrame to store the strategy information\n",
    "    # The net returns are (long - short)/2, since there is twice \n",
    "    # trading capital for this strategy\n",
    "    strat = pd.DataFrame(index=tick.index)\n",
    "    strat['net_ret'] = (tick['daily_ret'] - bench['daily_ret'])/2.0\n",
    "    \n",
    "    # Return the annualised Sharpe ratio for this strategy\n",
    "    return annualised_sharpe(strat['net_ret'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
