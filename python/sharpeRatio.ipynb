{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MySQLdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6dc4fb37926c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mMySQLdb\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mceil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MySQLdb'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import lxml.html\n",
    "import MySQLdb as mdb\n",
    "\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_parse_wiki_snp500():\n",
    "  \"\"\" Download and parse the Wikipedia list of S&P500 \n",
    "  constituents using requests and libxml.\n",
    "\n",
    "  Returns a list of tuples for to add to MySQL.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores the current time, for the created_at record\n",
    "now = datetime.datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error reading file 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies': failed to load external entity \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9f5317e0bdb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use libxml to download the list of S&P500 companies and obtain the symbol table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msymbolslist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//table[1]/tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lxml/html/__init__.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(filename_or_url, parser, base_url, **kw)\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree.parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocument\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocumentFromURL\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocFromFile\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._BaseParser._parseDocFromFile\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._ParserContext._handleParseResultDoc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._raiseParseError\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Error reading file 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies': failed to load external entity \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\""
     ]
    }
   ],
   "source": [
    "# Use libxml to download the list of S&P500 companies and obtain the symbol table\n",
    "\n",
    "page = lxml.html.parse('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "symbolslist = page.xpath('//table[1]/tr')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'symbolslist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cd62c5a2dc86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msymbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msymbol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msymbolslist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     sd = {'ticker': tds[0].getchildren()[0].text,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'symbolslist' is not defined"
     ]
    }
   ],
   "source": [
    "# Obtain the symbol information for each row in the S&P500 constituent table\n",
    "symbols = []\n",
    "\n",
    "for symbol in symbolslist:\n",
    "    tds = symbol.getchildren()\n",
    "    sd = {'ticker': tds[0].getchildren()[0].text,\n",
    "        'name': tds[1].getchildren()[0].text,\n",
    "        'sector': tds[3].text}\n",
    "\n",
    "    # Create a tuple (for the DB format) and append to the grand list\n",
    "    symbols.append( (sd['ticker'], 'stock', sd['name'], \n",
    "      sd['sector'], 'USD', now, now) )\n",
    "return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_snp500_symbols(symbols):\n",
    "  \"\"\"Insert the S&P500 symbols into the MySQL database.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MySQL instance\n",
    "db_host = 'localhost'\n",
    "db_user = 'sec_user'\n",
    "db_pass = 'password'\n",
    "db_name = 'securities_master'\n",
    "con = mdb.connect(host=db_host, user=db_user, passwd=db_pass, db=db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the insert strings\n",
    "column_str = \"ticker, instrument, name, sector, currency, created_date, last_updated_date\"\n",
    "insert_str = (\"%s, \" * 7)[:-2]\n",
    "final_str = \"INSERT INTO symbol (%s) VALUES (%s)\" % (column_str, insert_str)\n",
    "print final_str, len(symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the MySQL connection, carry out an INSERT INTO for every symbol\n",
    "\n",
    "with con: \n",
    "    cur = con.cursor()\n",
    "    # This line avoids the MySQL MAX_PACKET_SIZE\n",
    "    # Although of course it could be set larger!\n",
    "    \n",
    "    for i in range(0, int(ceil(len(symbols) / 100.0))):\n",
    "        cur.executemany(final_str, symbols[i*100:(i+1)*100-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  symbols = obtain_parse_wiki_snp500()\n",
    "  insert_snp500_symbols(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import MySQLdb as mdb\n",
    "import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a database connection to the MySQL instance\n",
    "\n",
    "db_host = 'localhost'\n",
    "db_user = 'sec_user'\n",
    "db_pass = 'password'\n",
    "db_name = 'securities_master'\n",
    "con = mdb.connect(db_host, db_user, db_pass, db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_list_of_db_tickers():\n",
    "  # Obtains a list of the ticker symbols in the database.\n",
    "  with con: \n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"SELECT id, ticker FROM symbol\")\n",
    "        data = cur.fetchall()\n",
    "        return [(d[0], d[1]) for d in data]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_historic_data_yahoo(ticker,\n",
    "                      start_date=(2000,1,1),\n",
    "                      end_date=datetime.date.today().timetuple()[0:3]):\n",
    "\n",
    "    \"\"\" \n",
    "    Obtains data from Yahoo Finance returns and a list of tuples.\n",
    "    ticker: Yahoo Finance ticker symbol, e.g. \"GOOG\" for Google, Inc.\n",
    "    start_date: Start date in (YYYY, M, D) format\n",
    "    end_date: End date in (YYYY, M, D) format\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Yahoo URL with the correct integer query parameters\n",
    "# for start and end dates. Note that some parameters are zero-based!\n",
    "\n",
    "yahoo_url = \"http://ichart.finance.yahoo.com/table.csv?s=%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s\" % \\\n",
    "      (ticker, start_date[1] - 1, start_date[2], start_date[0], end_date[1] - 1, end_date[2], end_date[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try connecting to Yahoo Finance and obtaining the data\n",
    "# On failure, print an error message.\n",
    "    try:\n",
    "        yf_data = urllib.urlopen(yahoo_url).readlines()[1:] # Ignore the header\n",
    "        prices = []\n",
    "        for y in yf_data:\n",
    "            p = y.strip().split(',')\n",
    "            prices.append( (datetime.datetime.strptime(p[0], '%Y-%m-%d'),\n",
    "                            p[1], p[2], p[3], p[4], p[5], p[6]) )\n",
    "    except Exception, e:\n",
    "        print (\"Could not download Yahoo data: %s\" % e)\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_daily_data_into_db(data_vendor_id, symbol_id, daily_data):\n",
    "  \"\"\"\n",
    "  Takes a list of tuples of daily data and adds it to the\n",
    "  MySQL database. Appends the vendor ID and symbol ID to the data.\n",
    "\n",
    "  daily_data: List of tuples of the OHLC data (with \n",
    "  adj_close and volume)\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the time now\n",
    "now = datetime.datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amend the data to include the vendor ID and symbol ID\n",
    "daily_data = [(data_vendor_id, symbol_id, d[0], now, now,\n",
    "               d[1], d[2], d[3], d[4], d[5], d[6]) for d in daily_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the insert strings\n",
    "column_str = \"\"\"data_vendor_id, symbol_id, price_date, created_date, \n",
    "             last_updated_date, open_price, high_price, low_price, \n",
    "             close_price, volume, adj_close_price\"\"\"\n",
    "insert_str = (\"%s, \" * 11)[:-2]\n",
    "\n",
    "final_str = \"INSERT INTO daily_price (%s) VALUES (%s)\" % (column_str, insert_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the MySQL connection, carry out an INSERT INTO for every symbol\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    cur.executemany(final_str, daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  # Loop over the tickers and insert the daily historical\n",
    "  # data into the database\n",
    "    \n",
    "    tickers = obtain_list_of_db_tickers()\n",
    "    for t in tickers:\n",
    "        print (\"Adding data for %s\" % t[1])\n",
    "\n",
    "        yf_data = get_daily_historic_data_yahoo(t[1])\n",
    "        insert_daily_data_into_db('1', t[0], yf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    yf_data = urllib.urlopen(yahoo_url).readlines()\n",
    "except Exception, e:\n",
    "    print (\"Could not download Yahoo data: %s\" % e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the (temporary) Python data structures to store the historical data\n",
    "date_list = []\n",
    "hist_data = [[] for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format and copy the raw text data into datetime objects\n",
    "# and floating point values (still in native Python lists)\n",
    "\n",
    "for day in yf_data[1:]:  # Avoid the header line in the CSV\n",
    "    headers = day.rstrip().split(',')\n",
    "    date_list.append(datetime.datetime.strptime(headers[0],'%Y-%m-%d'))\n",
    "    for i, header in enumerate(headers[1:]):\n",
    "        hist_data[i].append(float(header))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Python dictionary of the lists and then use that to\n",
    "# form a sorted Pandas DataFrame of the historical data\n",
    "hist_data = dict(zip(['open', 'high', 'low', 'close', 'volume', 'adj_close'], hist_data))\n",
    "pdf = pd.DataFrame(hist_data, index=pd.Index(date_list)).sort()\n",
    "\n",
    "return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annualised_sharpe(returns, N=252):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the annualised Sharpe ratio of a returns stream \n",
    "    based on a number of trading periods, N. N defaults to 252,\n",
    "    which then assumes a stream of daily returns.\n",
    "\n",
    "    The function assumes that the returns are the excess of \n",
    "    those compared to a benchmark.\n",
    "    \"\"\"\n",
    "    return np.sqrt(N) * returns.mean() / returns.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equity_sharpe(ticker):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the annualised Sharpe ratio based on the daily\n",
    "    returns of an equity ticker symbol listed in Yahoo Finance.\n",
    "\n",
    "    The dates have been hardcoded here for the QuantStart article \n",
    "    on Sharpe ratios.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtain the equities daily historic data for the desired time period\n",
    "    # and add to a pandas DataFrame\n",
    "    pdf = get_historic_data(ticker, start_date=(2000,1,1), end_date=(2013,5,29))\n",
    "\n",
    "    # Use the percentage change method to easily calculate daily returns\n",
    "    pdf['daily_ret'] = pdf['adj_close'].pct_change()\n",
    "\n",
    "    # Assume an average annual risk-free rate over the period of 5%\n",
    "    pdf['excess_daily_ret'] = pdf['daily_ret'] - 0.05/252\n",
    "\n",
    "    # Return the annualised Sharpe ratio based on the excess daily returns\n",
    "    return annualised_sharpe(pdf['excess_daily_ret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_neutral_sharpe(ticker, benchmark):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the annualised Sharpe ratio of a market\n",
    "    neutral long/short strategy inolving the long of 'ticker'\n",
    "    with a corresponding short of the 'benchmark'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get historic data for both a symbol/ticker and a benchmark ticker\n",
    "    # The dates have been hardcoded, but you can modify them as you see fit!\n",
    "    tick = get_historic_data(ticker, start_date=(2000,1,1), end_date=(2013,5,29))\n",
    "    bench = get_historic_data(benchmark, start_date=(2000,1,1), end_date=(2013,5,29))\n",
    "    \n",
    "    # Calculate the percentage returns on each of the time series\n",
    "    tick['daily_ret'] = tick['adj_close'].pct_change()\n",
    "    bench['daily_ret'] = bench['adj_close'].pct_change()\n",
    "    \n",
    "    # Create a new DataFrame to store the strategy information\n",
    "    # The net returns are (long - short)/2, since there is twice \n",
    "    # trading capital for this strategy\n",
    "    strat = pd.DataFrame(index=tick.index)\n",
    "    strat['net_ret'] = (tick['daily_ret'] - bench['daily_ret'])/2.0\n",
    "    \n",
    "    # Return the annualised Sharpe ratio for this strategy\n",
    "    return annualised_sharpe(strat['net_ret'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
