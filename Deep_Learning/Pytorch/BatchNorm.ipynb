{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B8F749E4C954AD8AFE6B96DD1F8B830",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Batch Normalization\n",
    "\n",
    "Just like the normalization for input data to improve model performance, now we perform BN during NN model traning to solve internal covariance shift and make convergence faster, can also be used as regularization method.\n",
    "\n",
    "The main idea of BatchNorm is this: for the current minibatch while training, in each hidden layer, we normalize the activations so that its distribution is Standard Normal (zero mean and one standard deviation). \n",
    "\n",
    "Then, we apply a linear transform to it with learned parameters so that the network could learn what kind of distribution is the best for the layer’s activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3E15ABE688814DCB811DF2D4D3A0BBDB",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Full Connection Layer：**  \n",
    "$$\n",
    "\\boldsymbol{x} = \\boldsymbol{W\\boldsymbol{u} + \\boldsymbol{b}} \\\\\n",
    " output =\\phi(\\boldsymbol{x})\n",
    " $$   \n",
    "\n",
    "\n",
    "**BN：**\n",
    "$$ \n",
    "output=\\phi(\\text{BN}(\\boldsymbol{x}))$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{y}^{(i)} = \\text{BN}(\\boldsymbol{x}^{(i)})\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\mu}_\\mathcal{B} \\leftarrow \\frac{1}{m}\\sum_{i = 1}^{m} \\boldsymbol{x}^{(i)},\n",
    "$$ \n",
    "$$\n",
    "\\boldsymbol{\\sigma}_\\mathcal{B}^2 \\leftarrow \\frac{1}{m} \\sum_{i=1}^{m}(\\boldsymbol{x}^{(i)} - \\boldsymbol{\\mu}_\\mathcal{B})^2,\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{x}}^{(i)} \\leftarrow \\frac{\\boldsymbol{x}^{(i)} - \\boldsymbol{\\mu}_\\mathcal{B}}{\\sqrt{\\boldsymbol{\\sigma}_\\mathcal{B}^2 + \\epsilon}},\n",
    "$$\n",
    "\n",
    "Here, ϵ>0 is to ensure the denominator is greater than 0.\n",
    "\n",
    "\n",
    "$$\n",
    "{\\boldsymbol{y}}^{(i)} \\leftarrow \\boldsymbol{\\gamma} \\odot\n",
    "\\hat{\\boldsymbol{x}}^{(i)} + \\boldsymbol{\\beta}.\n",
    "$$\n",
    "\n",
    "Then the result input x is squashed through a linear function with learnable parameters: the scale param(gamma) γ and shift param(beta) β\n",
    "\n",
    "If gamma = sqrt(var(x)) and beta = mean(x), the original activation is restored. \n",
    "\n",
    "\n",
    "\n",
    "### For Conv Layer\n",
    "After conv layer, before activation layer\n",
    "\n",
    "If the output has multiple channels, we need to perform separately, each channel has different params \n",
    "\n",
    "Conv_out_put.Shape: **channel_num * conv_output_size(height*width) * batch_size**\n",
    "\n",
    "Calculation: for each channel, BN on batch_size**conv_output_size(height*width)\n",
    "\n",
    "\n",
    "### For Prediction\n",
    "- Use EMA to estimate mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "96E72C7A9429485180F9B63F7FB07CB9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import sys\n",
    "sys.path.append(\"/home/kesci/input/\") \n",
    "import d2lzh1981 as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batch_norm(is_training, X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # see if training mode or not\n",
    "    if not is_training:\n",
    "        # if in prediction, use Moving Average to calculate mean & std\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2: # dim=2, mean the FC layer\n",
    "            # calculate mean & std on dim = 0\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else: # dim=4, Conv layer,\n",
    "            # calculate the mean & std on channel dim(axis=1), has the same dim as channel_num\n",
    "            # keep the shape of X for broadcast operations\n",
    "            mean = X.mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n",
    "        # in traninf mode, use the current mean & std to normalization\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # update moving average mean & std\n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean # momentum is pre-defined param\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
    "    \n",
    "    Y = gamma * X_hat + beta  # scale and shift\n",
    "    \n",
    "    return Y, moving_mean, moving_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "04A65ABC9F20404E83F166F43226873D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super(BatchNorm, self).__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features) # FC layer output neurons\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)  # channel num\n",
    "        # initialize scale param to one, shift param to zero\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        # initialize param for prediction to zero(no grad needed)\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.zeros(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # if X is not on the memory, copy moving_mean&moving_var to device\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # save updated moving_mean&moving_var\n",
    "        # self.traning default is true, if .eval() set to false\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(self.training, \n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.9)\n",
    "            \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FE611706B7F4C1B8B57182BC1CE450B",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Implemented on LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1B18E8F1B4C843E6852A0B50CFFD9C53",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): BatchNorm()\n",
      "  (2): Sigmoid()\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (5): BatchNorm()\n",
      "  (6): Sigmoid()\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): FlattenLayer()\n",
      "  (9): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (10): BatchNorm()\n",
      "  (11): Sigmoid()\n",
      "  (12): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (13): BatchNorm()\n",
      "  (14): Sigmoid()\n",
      "  (15): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            BatchNorm(6, num_dims=4), # num_dims=4 after conv\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            BatchNorm(16, num_dims=4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            d2l.FlattenLayer(),\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            BatchNorm(120, num_dims=2), # after FC\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            BatchNorm(84, num_dims=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "F11883676ED64A2DB05BC3480AF28BFF",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128  \n",
    "## if on cpu, the batchsize should be lower\n",
    "# batch_size = 16\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root='/home/kesci/input/FashionMNIST2065'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    \n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9F9DC5C22F5942A48A8A4B656B33D543",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.0311, train acc 0.990, test acc 0.890, time 7.5 sec\n",
      "epoch 2, loss 0.0315, train acc 0.990, test acc 0.894, time 7.9 sec\n",
      "epoch 3, loss 0.0263, train acc 0.993, test acc 0.888, time 7.8 sec\n",
      "epoch 4, loss 0.0274, train acc 0.992, test acc 0.892, time 7.9 sec\n",
      "epoch 5, loss 0.0293, train acc 0.991, test acc 0.891, time 7.7 sec\n",
      "epoch 6, loss 0.0258, train acc 0.992, test acc 0.891, time 7.9 sec\n",
      "epoch 7, loss 0.0257, train acc 0.992, test acc 0.890, time 7.6 sec\n",
      "epoch 8, loss 0.0246, train acc 0.992, test acc 0.891, time 7.5 sec\n",
      "epoch 9, loss 0.0264, train acc 0.992, test acc 0.888, time 7.9 sec\n",
      "epoch 10, loss 0.0248, train acc 0.992, test acc 0.888, time 8.0 sec\n",
      "epoch 11, loss 0.0224, train acc 0.993, test acc 0.890, time 7.5 sec\n",
      "epoch 12, loss 0.0237, train acc 0.993, test acc 0.889, time 8.1 sec\n",
      "epoch 13, loss 0.0206, train acc 0.994, test acc 0.889, time 7.6 sec\n",
      "epoch 14, loss 0.0230, train acc 0.993, test acc 0.891, time 7.8 sec\n",
      "epoch 15, loss 0.0202, train acc 0.994, test acc 0.897, time 7.6 sec\n",
      "epoch 16, loss 0.0207, train acc 0.994, test acc 0.889, time 7.9 sec\n",
      "epoch 17, loss 0.0196, train acc 0.994, test acc 0.890, time 7.3 sec\n",
      "epoch 18, loss 0.0206, train acc 0.994, test acc 0.891, time 8.2 sec\n",
      "epoch 19, loss 0.0222, train acc 0.993, test acc 0.892, time 8.1 sec\n",
      "epoch 20, loss 0.0196, train acc 0.994, test acc 0.895, time 7.8 sec\n",
      "epoch 21, loss 0.0189, train acc 0.995, test acc 0.894, time 7.8 sec\n",
      "epoch 22, loss 0.0186, train acc 0.995, test acc 0.892, time 8.0 sec\n",
      "epoch 23, loss 0.0168, train acc 0.995, test acc 0.894, time 8.0 sec\n",
      "epoch 24, loss 0.0160, train acc 0.996, test acc 0.892, time 7.9 sec\n",
      "epoch 25, loss 0.0202, train acc 0.994, test acc 0.885, time 7.8 sec\n",
      "epoch 26, loss 0.0184, train acc 0.995, test acc 0.892, time 7.6 sec\n",
      "epoch 27, loss 0.0161, train acc 0.995, test acc 0.892, time 8.1 sec\n",
      "epoch 28, loss 0.0162, train acc 0.995, test acc 0.891, time 7.9 sec\n",
      "epoch 29, loss 0.0162, train acc 0.995, test acc 0.891, time 8.0 sec\n",
      "epoch 30, loss 0.0192, train acc 0.994, test acc 0.892, time 8.1 sec\n",
      "epoch 31, loss 0.0162, train acc 0.995, test acc 0.894, time 7.2 sec\n",
      "epoch 32, loss 0.0146, train acc 0.996, test acc 0.886, time 7.7 sec\n",
      "epoch 33, loss 0.0145, train acc 0.996, test acc 0.884, time 7.7 sec\n",
      "epoch 34, loss 0.0178, train acc 0.994, test acc 0.885, time 7.7 sec\n",
      "epoch 35, loss 0.0171, train acc 0.994, test acc 0.890, time 7.8 sec\n",
      "epoch 36, loss 0.0145, train acc 0.996, test acc 0.889, time 8.1 sec\n",
      "epoch 37, loss 0.0135, train acc 0.996, test acc 0.883, time 8.0 sec\n",
      "epoch 38, loss 0.0150, train acc 0.995, test acc 0.886, time 7.6 sec\n",
      "epoch 39, loss 0.0121, train acc 0.997, test acc 0.885, time 8.0 sec\n",
      "epoch 40, loss 0.0172, train acc 0.994, test acc 0.889, time 7.6 sec\n",
      "epoch 41, loss 0.0180, train acc 0.994, test acc 0.893, time 7.9 sec\n",
      "epoch 42, loss 0.0135, train acc 0.996, test acc 0.892, time 7.8 sec\n",
      "epoch 43, loss 0.0134, train acc 0.996, test acc 0.893, time 8.0 sec\n",
      "epoch 44, loss 0.0140, train acc 0.996, test acc 0.890, time 8.1 sec\n",
      "epoch 45, loss 0.0138, train acc 0.996, test acc 0.894, time 8.1 sec\n",
      "epoch 46, loss 0.0124, train acc 0.997, test acc 0.894, time 8.1 sec\n",
      "epoch 47, loss 0.0126, train acc 0.996, test acc 0.880, time 8.1 sec\n",
      "epoch 48, loss 0.0138, train acc 0.996, test acc 0.878, time 7.6 sec\n",
      "epoch 49, loss 0.0157, train acc 0.995, test acc 0.893, time 7.8 sec\n",
      "epoch 50, loss 0.0095, train acc 0.998, test acc 0.890, time 8.1 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 50\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AC692570D35A492BB82A50E9BBBBB598",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Built-in Batch Norm Function in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EAC5ACDF548B4831992A653DF4FD4348",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 1.0832, train acc 0.790, test acc 0.801, time 7.7 sec\n",
      "epoch 2, loss 0.4375, train acc 0.866, test acc 0.849, time 7.5 sec\n",
      "epoch 3, loss 0.3486, train acc 0.881, test acc 0.825, time 7.1 sec\n",
      "epoch 4, loss 0.3180, train acc 0.891, test acc 0.866, time 7.2 sec\n",
      "epoch 5, loss 0.2981, train acc 0.895, test acc 0.874, time 7.1 sec\n",
      "epoch 6, loss 0.2840, train acc 0.899, test acc 0.852, time 7.1 sec\n",
      "epoch 7, loss 0.2741, train acc 0.903, test acc 0.862, time 7.0 sec\n",
      "epoch 8, loss 0.2648, train acc 0.906, test acc 0.834, time 7.1 sec\n",
      "epoch 9, loss 0.2560, train acc 0.908, test acc 0.861, time 7.6 sec\n",
      "epoch 10, loss 0.2480, train acc 0.911, test acc 0.789, time 6.9 sec\n",
      "epoch 11, loss 0.2421, train acc 0.913, test acc 0.885, time 6.8 sec\n",
      "epoch 12, loss 0.2345, train acc 0.915, test acc 0.857, time 6.8 sec\n",
      "epoch 13, loss 0.2301, train acc 0.917, test acc 0.837, time 6.9 sec\n",
      "epoch 14, loss 0.2237, train acc 0.920, test acc 0.823, time 6.9 sec\n",
      "epoch 15, loss 0.2184, train acc 0.921, test acc 0.860, time 6.9 sec\n",
      "epoch 16, loss 0.2147, train acc 0.921, test acc 0.885, time 6.9 sec\n",
      "epoch 17, loss 0.2068, train acc 0.925, test acc 0.874, time 6.9 sec\n",
      "epoch 18, loss 0.2037, train acc 0.926, test acc 0.888, time 6.9 sec\n",
      "epoch 19, loss 0.1987, train acc 0.928, test acc 0.880, time 6.9 sec\n",
      "epoch 20, loss 0.1959, train acc 0.929, test acc 0.886, time 6.9 sec\n",
      "epoch 21, loss 0.1909, train acc 0.930, test acc 0.897, time 6.9 sec\n",
      "epoch 22, loss 0.1868, train acc 0.932, test acc 0.886, time 6.9 sec\n",
      "epoch 23, loss 0.1821, train acc 0.933, test acc 0.880, time 6.9 sec\n",
      "epoch 24, loss 0.1792, train acc 0.935, test acc 0.876, time 6.9 sec\n",
      "epoch 25, loss 0.1762, train acc 0.936, test acc 0.884, time 6.9 sec\n",
      "epoch 26, loss 0.1701, train acc 0.938, test acc 0.887, time 6.9 sec\n",
      "epoch 27, loss 0.1674, train acc 0.938, test acc 0.897, time 6.9 sec\n",
      "epoch 28, loss 0.1626, train acc 0.940, test acc 0.884, time 7.0 sec\n",
      "epoch 29, loss 0.1595, train acc 0.941, test acc 0.880, time 7.0 sec\n",
      "epoch 30, loss 0.1571, train acc 0.942, test acc 0.874, time 6.9 sec\n",
      "epoch 31, loss 0.1510, train acc 0.945, test acc 0.874, time 7.0 sec\n",
      "epoch 32, loss 0.1485, train acc 0.945, test acc 0.880, time 7.0 sec\n",
      "epoch 33, loss 0.1439, train acc 0.947, test acc 0.808, time 6.9 sec\n",
      "epoch 34, loss 0.1421, train acc 0.948, test acc 0.880, time 7.0 sec\n",
      "epoch 35, loss 0.1382, train acc 0.949, test acc 0.887, time 6.9 sec\n",
      "epoch 36, loss 0.1330, train acc 0.952, test acc 0.889, time 6.9 sec\n",
      "epoch 37, loss 0.1314, train acc 0.953, test acc 0.872, time 6.9 sec\n",
      "epoch 38, loss 0.1264, train acc 0.954, test acc 0.882, time 7.0 sec\n",
      "epoch 39, loss 0.1251, train acc 0.954, test acc 0.893, time 6.9 sec\n",
      "epoch 40, loss 0.1221, train acc 0.955, test acc 0.891, time 6.9 sec\n",
      "epoch 41, loss 0.1185, train acc 0.957, test acc 0.879, time 6.9 sec\n",
      "epoch 42, loss 0.1134, train acc 0.958, test acc 0.879, time 7.0 sec\n",
      "epoch 43, loss 0.1123, train acc 0.959, test acc 0.887, time 6.8 sec\n",
      "epoch 44, loss 0.1072, train acc 0.961, test acc 0.880, time 6.9 sec\n",
      "epoch 45, loss 0.1054, train acc 0.962, test acc 0.889, time 6.9 sec\n",
      "epoch 46, loss 0.1007, train acc 0.964, test acc 0.889, time 6.9 sec\n",
      "epoch 47, loss 0.0985, train acc 0.965, test acc 0.882, time 6.9 sec\n",
      "epoch 48, loss 0.0945, train acc 0.967, test acc 0.880, time 6.9 sec\n",
      "epoch 49, loss 0.0910, train acc 0.968, test acc 0.887, time 6.9 sec\n",
      "epoch 50, loss 0.0880, train acc 0.968, test acc 0.887, time 7.0 sec\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            nn.BatchNorm2d(6), # batchNorm2d means after conv2d\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            d2l.FlattenLayer(),\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            nn.BatchNorm1d(120), # batchNorm1d means after fc\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "50F442253C51495181611BB088576C75",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## ResNet\n",
    "In CNN, when neural network reaches certain depth, more layers cannot improve performance, instead only make model worse.\n",
    "\n",
    "### Residual Block\n",
    "Left：f(x)=x                                                  \n",
    "Right：f(x)-x=0 \n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l8lhnot4.png?imageView2/0/w/600/h/600)\n",
    "\n",
    "Using Residual Block can make input across layers and move forward faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3F859601FD264D1A8D5E5E51B9D83D0D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):  \n",
    "    # define output_channel, if use extra 1x1 conv layer to change stride for channels or conv layers。\n",
    "    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n",
    "        super(Residual, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X) # reshape X to the same size of Y\n",
    "        return F.relu(Y + X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2E2CF8846F5C43618B6DB004FA95BC0E",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 6, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3, 3)\n",
    "X = torch.rand((4, 3, 6, 6))\n",
    "blk(X).shape \n",
    "# torch.Size([4, 3, 6, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "C8F6DFFB58344B669C24A18721B8A66F",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 3, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3, 6, use_1x1conv=True, stride=2)\n",
    "blk(X).shape \n",
    "# torch.Size([4, 6, 3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEFB948C07AE428D8F5F756CDE556CF9",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### ResNet Model\n",
    "Conv (64, 7x7, 3)  \n",
    "Batch Norm \n",
    "ReLU\n",
    "MaxPooling (3x3, 2)  \n",
    "\n",
    "Residual Blockx4 (use residual block of stride 2 to reduce height and width between blocks)\n",
    "Global Average Pooling\n",
    "Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6117AE144A6B4EF58B382D31F1C2F760",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "D1E8052B1A8242F285BDD3E54418419B",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n",
    "    if first_block:\n",
    "        assert in_channels == out_channels # the first block should have same input_channel/output_channel num\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_channels, out_channels))\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
    "net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
    "net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "93D7FFC7581F438A82E92D85E3F6D24E",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net.add_module(\"global_avg_pool\", d2l.GlobalAvgPool2d()) # GlobalAvgPool2d output: (Batch, 512, 1, 1)\n",
    "net.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(), nn.Linear(512, 10))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "EE1FD4E1510941AB98B3C8840DA47E44",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  output shape:\t torch.Size([1, 64, 112, 112])\n",
      "1  output shape:\t torch.Size([1, 64, 112, 112])\n",
      "2  output shape:\t torch.Size([1, 64, 112, 112])\n",
      "3  output shape:\t torch.Size([1, 64, 56, 56])\n",
      "resnet_block1  output shape:\t torch.Size([1, 64, 56, 56])\n",
      "resnet_block2  output shape:\t torch.Size([1, 128, 28, 28])\n",
      "resnet_block3  output shape:\t torch.Size([1, 256, 14, 14])\n",
      "resnet_block4  output shape:\t torch.Size([1, 512, 7, 7])\n",
      "global_avg_pool  output shape:\t torch.Size([1, 512, 1, 1])\n",
      "fc  output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# example of an image's feature map changethrough resnet model\n",
    "X = torch.rand((1, 1, 224, 224))\n",
    "for name, layer in net.named_children():\n",
    "    X = layer(X)\n",
    "    print(name, ' output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7A68C8B9480C4DB8935436EC136068F1",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.4184, train acc 0.847, test acc 0.839, time 152.5 sec\n",
      "epoch 2, loss 0.2985, train acc 0.890, test acc 0.886, time 151.6 sec\n",
      "epoch 3, loss 0.2628, train acc 0.903, test acc 0.887, time 151.6 sec\n",
      "epoch 4, loss 0.2348, train acc 0.912, test acc 0.898, time 151.5 sec\n",
      "epoch 5, loss 0.2130, train acc 0.922, test acc 0.903, time 152.6 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "610FDA7246E64E6AAA8669EEDEA33BB1",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## DenseNet\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l8mi78yz.png?imageView2/0/w/600/h/600)\n",
    "\n",
    "#### Main Blocks：  \n",
    "Dense block：define the concatenation of input and output \n",
    "Transition layer：control channel_num not too large "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "644303248ACD46C9886553FB41750A4F",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels): # for simpler use in below densenet model\n",
    "    blk = nn.Sequential(nn.BatchNorm2d(in_channels), \n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "    return blk\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_convs, in_channels, out_channels): # num_convs is the num of above conv_block\n",
    "        super(DenseBlock, self).__init__()\n",
    "        net = []\n",
    "        for i in range(num_convs):\n",
    "            in_c = in_channels + i * out_channels # concatenation\n",
    "            net.append(conv_block(in_c, out_channels))\n",
    "        self.net = nn.ModuleList(net)\n",
    "        self.out_channels = in_channels + num_convs * out_channels # calculate out_channel num\n",
    "\n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            X = torch.cat((X, Y), dim=1)  # concat input and output on the channel dim\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "72F1294D9DDD454D9831BCA94764B9DE",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 8, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = DenseBlock(2, 3, 10)\n",
    "X = torch.rand(4, 3, 8, 8)\n",
    "Y = blk(X)\n",
    "Y.shape \n",
    "# torch.Size([4, 23, 8, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23FDE43573EA40389189D2D4659A59D9",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Transition Block\n",
    "\n",
    "$1\\times1$ Conv layer：to reduce channel num\n",
    "stride: 2 AvgPool：halve the height & width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ED891AD5805040F6A93AD06B1E7C0FA8",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 4, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transition_block(in_channels, out_channels):\n",
    "    blk = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "    return blk\n",
    "\n",
    "blk = transition_block(23, 10)\n",
    "blk(Y).shape \n",
    "# torch.Size([4, 10, 4, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE6DADC26CE04D2C86F49867321D491F",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### DenseNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "E32E30B6657E4CB5B3027B663927AA83",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8464B9866CBF4EB280381A63A9F4557E",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_channels, growth_rate = 64, 32  # num_channels is current channel number\n",
    "num_convs_in_dense_blocks = [4, 4, 4, 4]\n",
    "\n",
    "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
    "    DB = DenseBlock(num_convs, num_channels, growth_rate)\n",
    "    net.add_module(\"DenseBlosk_%d\" % i, DB)\n",
    "    # last dense block ouput_channel num\n",
    "    num_channels = DB.out_channels\n",
    "    # add transition block with half of the channels between dense block\n",
    "    if i != len(num_convs_in_dense_blocks) - 1:\n",
    "        net.add_module(\"transition_block_%d\" % i, transition_block(num_channels, num_channels // 2))\n",
    "        num_channels = num_channels // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "76C89C4331674B8C8F531F4157CACAB1",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  output shape:\t torch.Size([1, 64, 48, 48])\n",
      "1  output shape:\t torch.Size([1, 64, 48, 48])\n",
      "2  output shape:\t torch.Size([1, 64, 48, 48])\n",
      "3  output shape:\t torch.Size([1, 64, 24, 24])\n",
      "DenseBlosk_0  output shape:\t torch.Size([1, 192, 24, 24])\n",
      "transition_block_0  output shape:\t torch.Size([1, 96, 12, 12])\n",
      "DenseBlosk_1  output shape:\t torch.Size([1, 224, 12, 12])\n",
      "transition_block_1  output shape:\t torch.Size([1, 112, 6, 6])\n",
      "DenseBlosk_2  output shape:\t torch.Size([1, 240, 6, 6])\n",
      "transition_block_2  output shape:\t torch.Size([1, 120, 3, 3])\n",
      "DenseBlosk_3  output shape:\t torch.Size([1, 248, 3, 3])\n",
      "BN  output shape:\t torch.Size([1, 248, 3, 3])\n",
      "relu  output shape:\t torch.Size([1, 248, 3, 3])\n",
      "global_avg_pool  output shape:\t torch.Size([1, 248, 1, 1])\n",
      "fc  output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "net.add_module(\"BN\", nn.BatchNorm2d(num_channels))\n",
    "net.add_module(\"relu\", nn.ReLU())\n",
    "net.add_module(\"global_avg_pool\", d2l.GlobalAvgPool2d()) # GlobalAvgPool2d output: (Batch, num_channels, 1, 1)\n",
    "net.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(), nn.Linear(num_channels, 10))) \n",
    "\n",
    "X = torch.rand((1, 1, 96, 96))\n",
    "for name, layer in net.named_children():\n",
    "    X = layer(X)\n",
    "    print(name, ' output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "F70449A99F984956B8BEC295A53E0A99",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.1900, train acc 0.931, test acc 0.911, time 67.1 sec\n",
      "epoch 2, loss 0.1721, train acc 0.938, test acc 0.912, time 67.4 sec\n",
      "epoch 3, loss 0.1597, train acc 0.941, test acc 0.887, time 67.6 sec\n",
      "epoch 4, loss 0.1496, train acc 0.945, test acc 0.919, time 67.7 sec\n",
      "epoch 5, loss 0.1379, train acc 0.950, test acc 0.925, time 67.7 sec\n",
      "epoch 6, loss 0.1287, train acc 0.953, test acc 0.919, time 67.7 sec\n",
      "epoch 7, loss 0.1197, train acc 0.955, test acc 0.925, time 67.7 sec\n",
      "epoch 8, loss 0.1111, train acc 0.959, test acc 0.910, time 67.8 sec\n",
      "epoch 9, loss 0.1022, train acc 0.962, test acc 0.932, time 67.7 sec\n",
      "epoch 10, loss 0.0939, train acc 0.965, test acc 0.912, time 67.7 sec\n",
      "epoch 11, loss 0.0864, train acc 0.968, test acc 0.932, time 67.7 sec\n",
      "epoch 12, loss 0.0755, train acc 0.972, test acc 0.925, time 67.6 sec\n",
      "epoch 13, loss 0.0728, train acc 0.974, test acc 0.928, time 67.7 sec\n",
      "epoch 14, loss 0.0627, train acc 0.977, test acc 0.916, time 67.6 sec\n",
      "epoch 15, loss 0.0572, train acc 0.979, test acc 0.933, time 67.7 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_iter, test_iter =load_data_fashion_mnist(batch_size, resize=96)\n",
    "lr, num_epochs = 0.001, 15\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4C9A8750A7B4DC1A08B15C55DD5772E",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
