{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_on4eyh2",
    "id": "9E73B21214794A1B8F92AF2169A6F409",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Text Sentiment Analysis - 1\n",
    "\n",
    "\n",
    "Text classification is a common task in natural language processing, which transforms a sequence of text of indefinite length into a category of text. It is similar to the image classification. The only difference is that, rather than an image, text classification's example is a text sentence.\n",
    "\n",
    "This notebook will focus on one of the sub problems in this field: using text sentiment classification to analyze the emotions of the text's author. This problem is also called sentiment analysis and has a wide range of applications. For example, we can analyze user reviews of products to obtain user satisfaction statistics in E-commerce, or analyze user sentiments about market conditions and use it to predict future trends in Finance.\n",
    "\n",
    "\n",
    "Like searching for synonyms and analogies, text classification is also a popular application of word embedding. I will use pre-trained GloVe vectors and 2 models in this notebook : first a **bidirectional RNN (Recurrent Neural Network)** and then a **CNN (Convolutional Neural Network)** to determine whether a certain length of text sequence contains positive or negative emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A1256CCF9CFA4DF380CA46E53F7BDE74",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "graffitiCellId": "id_qpkl0v3",
    "id": "4C34DE8574664EBC876799AFFD97FACC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_75c1s0z",
    "id": "ECA9EC64CB6B4C0C8CCDB65ACD18D2BE",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### The Sentiment Analysis Dataset\n",
    "\n",
    "We use [Stanford's Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/) as the dataset for sentiment analysis. This dataset is divided into two datasets for training and testing purposes, each containing 25,000 movie reviews downloaded from IMDb. In each dataset, the number of comments labeled as \"positive\" and \"negative\" is equal, making it a quite balanced dataset.\n",
    "\n",
    "\n",
    "- Dataset file structure\n",
    "\n",
    "```\n",
    "| aclImdb_v1\n",
    "    | train\n",
    "    |   | pos\n",
    "    |   |   | 0_9.txt  \n",
    "    |   |   | 1_7.txt\n",
    "    |   |   | ...\n",
    "    |   | neg\n",
    "    |   |   | 0_3.txt\n",
    "    |   |   | 1_1.txt\n",
    "    |   | ...\n",
    "    | test\n",
    "    |   | pos\n",
    "    |   | neg\n",
    "    |   | ...\n",
    "    | ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "graffitiCellId": "id_nxrjw92",
    "id": "2D650272040243AA8AC04AA8BCC96645",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:00<00:00, 41725.80it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 41366.23it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 42091.20it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 41608.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t the fiendish plot of dr. fu manchu (1980). this is\n",
      "0 \t how do i begin to review a film that will soon be \n",
      "0 \t if you want an undemanding and reasonably amusing \n",
      "0 \t well since seeing part's 1 through 3 i can honestl\n",
      "1 \t spoiler alert! this movie, zero day, gives an insi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def read_imdb(folder='train', data_root=\"/home/kesci/input/IMDB2578/aclImdb_v1/aclImdb\"):\n",
    "    data = []\n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_name = os.path.join(data_root, folder, label)\n",
    "        for file in tqdm(os.listdir(folder_name)):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n', '').lower()\n",
    "                data.append([review, 1 if label == 'pos' else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "DATA_ROOT = \"/home/kesci/input/IMDB2578/aclImdb_v1/\"\n",
    "data_root = os.path.join(DATA_ROOT, \"aclImdb\")\n",
    "train_data, test_data = read_imdb('train', data_root), read_imdb('test', data_root)\n",
    "\n",
    "# print first 5 samples in the training set\n",
    "for sample in train_data[:5]:\n",
    "    print(sample[1], '\\t', sample[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "02FB2DCA103B4F22B1CC45DE98123CA7",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# trainings: 2\n",
      "label: how do i begin to review a film that will soon be recognized as the `worst film of all time' by the `worst director of all time?' a film that could develop a cult following because it's `so bad it's good?'<br /><br />an analytical approach criticizing the film seems both pointless and part of band-wagon syndrome--let's bash freely without worry of backlash because every other human on earth is doing it, and the people who like the film like it for those flaws we'd cite.<br /><br />the film's universal poor quality goes without saying-- 'sixteen years of alcohol' is not without competition for title of worst film so it has to sink pretty low to acquire the title and keep a hold of it, but i believe this film could go the distance. imdb doesn't allow enough words to cite all the films failures, and it be much easier to site the elements 'sixteen years of alcohol' does right. unfortunately, those moments of glory are so far buried in the shadows of this film's poorness that that's a task not worth pursuing.<br /><br />my impressions? i thought i knew what i was getting into, i had been warned to drink several cups of coffee before sitting down to watch this one (wish that suggestion had been cups of vodka). despite my low expectations, 'sixteen years of alcohol' failed to entertain me even on a `make fun of the bad movie' level. not just bad, but obnoxiously bad as though jobson intentionally tried to make this film a poetical yawn but went into overkill and shoved the poetry down our throats making it not profound but funny . .. and supposedly jobson sincerely tried to make a good movie? even after viewing the 'sixteen years of alcohol' promotional literature, i have trouble believing jobson's sincerity. pointless and obnoxious till the end with a several grin/chuckle moments (all i'm sure none intentional)spiced the film, and those few elements prevented me from turning the dvd off. so bad it's good? no. it had just enough 'i can't believe this is a serious movie moments' to keep me from turning it off, and nothing more.<br /><br />definitely a film to watch with a group of bad-movie connoisseurs. get your own running commentary going. that would've significantly improved the experience for me. so bad it's mike myers commentating in his cod scottish accent on it as it runs, to turn this whole piece of sludge into a comic farce \"ok dare ma man, pass me annuder gliss of dat wiskey\". review: the fiendish plot of dr. fu manchu (1980). this is hands dow\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ec12c9876622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# previe of the data\n",
    "print('# trainings:', len(train_data[0]))\n",
    "\n",
    "for x, y in zip(train_data[0][:3], train_data[1][:3]):\n",
    "    print('label:', y, 'review:', x[0:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_q12pdj4",
    "id": "27D596E884AD48778032BE5876EA56C7",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Preprocessing:  Tokenization and Vocabulary\n",
    "\n",
    "After reading the data, we first tokenize the text, and then use a word as a token to create a dictionary based on the training set using [`torchtext.vocab.Vocab`](https://torchtext.readthedocs.io/en/latest/vocab.html#vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "graffitiCellId": "id_f6u98c3",
    "id": "501A5FC9F17D49B084DE9C15B04233A3",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in vocab: 46152\n"
     ]
    }
   ],
   "source": [
    "def get_tokenized_imdb(data):\n",
    "    '''\n",
    "    @params:\n",
    "        data: each element is [string, 0/1 label] \n",
    "    @return: list after tokenization, each element is token sequence\n",
    "    '''\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower() for tok in text.split(' ')] # split by space\n",
    "    \n",
    "    return [tokenizer(review) for review, _ in data]\n",
    "\n",
    "def get_vocab_imdb(data):\n",
    "    '''\n",
    "    @params:\n",
    "        data: same as above\n",
    "    @return: vocab created on the dataset，instance as（freqs, stoi, itos）\n",
    "    '''\n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    counter = collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    return Vocab.Vocab(counter, min_freq=5)\n",
    "\n",
    "vocab = get_vocab_imdb(train_data)\n",
    "print('# words in vocab:', len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_9s26xhr",
    "id": "B6CDF2CC978D48F980E835392BAC8CF0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "After the vocab and the mapping of token to idx are created, the text can be converted from string to a sequence with idx for later use. Because the reviews have different lengths, so they cannot be directly combined into mini batches. Here we fix the length of each comment to 500 by truncating or padding to the samel length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "graffitiCellId": "id_3ejykvx",
    "id": "B8BDA6B5EE364F538022F97E8A1114FC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_imdb(data, vocab):\n",
    "    '''\n",
    "    @params:\n",
    "        data: raw input data\n",
    "        vocab: dictionary we just created\n",
    "    @return:\n",
    "        features: idx seq of token, shape is (n, max_l) int tensor\n",
    "        labels: emotions labels, shape is (n,) 0/1 int tensor\n",
    "    '''\n",
    "    max_l = 500  # sequence length we defined: 500\n",
    "\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x) > max_l else x + [0] * (max_l - len(x)) \n",
    "\n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    features = torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    labels = torch.tensor([score for _, score in data])\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_yge4ncq",
    "id": "D4189672985F4DA781725897C3395EBB",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Creating the data iterator\n",
    "\n",
    "Using [`torch.utils.data.TensorDataset`](https://pytorch.org/docs/stable/data.html?highlight=tensor%20dataset#torch.utils.data.TensorDataset) can create PyTorch format dataset and data iterator. Each iteration will return a minibatch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "graffitiCellId": "id_q2o053r",
    "id": "46970B8D972042009CC3393C59BCD4B6",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([64, 500]) y torch.Size([64])\n",
      "#batches: 391\n"
     ]
    }
   ],
   "source": [
    "train_set = Data.TensorDataset(*preprocess_imdb(train_data, vocab))\n",
    "test_set = Data.TensorDataset(*preprocess_imdb(test_data, vocab))\n",
    "\n",
    "# below is the code for same function as above\n",
    "# train_features, train_labels = preprocess_imdb(train_data, vocab)\n",
    "# test_features, test_labels = preprocess_imdb(test_data, vocab)\n",
    "# train_set = Data.TensorDataset(train_features, train_labels)\n",
    "# test_set = Data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "# preview \n",
    "# len(train_set) = features.shape[0] or labels.shape[0] \n",
    "# train_set[index] = (features[index], labels[index])\n",
    "\n",
    "batch_size = 64\n",
    "train_iter = Data.DataLoader(train_set, batch_size, shuffle=True) # shuffle the training set\n",
    "test_iter = Data.DataLoader(test_set, batch_size)\n",
    "\n",
    "for X, y in train_iter:\n",
    "    print('X', X.shape, 'y', y.shape)\n",
    "    break\n",
    "# preview\n",
    "print('#batches:', len(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_uu3a646",
    "id": "E5DAD388C64B49FF86DA61D202D5A104",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Recurrent Neural Network Model\n",
    "\n",
    "**- Using a Bidirectional RNN Model**\n",
    "\n",
    "In this model, each word first obtains a feature vector from the embedding layer. Then, we further encode the feature sequence using a bidirectional recurrent neural network to obtain sequence information. Finally, we transform the encoded sequence information to output through the fully connected layer. Specifically, we can concatenate hidden states of bidirectional long-short term memory in the initial timestep and final timestep and pass it to the output layer classification as encoded feature sequence information. In the BiRNN class implemented below, the Embedding instance is the embedding layer, the LSTM instance is the hidden layer for sequence encoding, and the Dense instance is the output layer for generated classification results.\n",
    "\n",
    "Let's quickly recap our Bi-RNN model: \n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5mnobct47.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5mo6okdnp.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "\n",
    "\n",
    "Given the input sequence $\\{\\boldsymbol{X}_1,\\boldsymbol{X}_2,\\dots,\\boldsymbol{X}_T\\}$，where $\\boldsymbol{X}_t\\in\\mathbb{R}^{n\\times d}$ is the time step（batch size is $n$，input dimension is $d$).\n",
    "\n",
    "In the Bi-RNN structure，let the forward hidden state at time step $t$ be $\\overrightarrow{\\boldsymbol{H}}_{t} \\in \\mathbb{R}^{n \\times h}$ (Forward hidden state dim: $h$), while the hidden state in reverse order is $\\overleftarrow{\\boldsymbol{H}}_{t} \\in \\mathbb{R}^{n \\times h}$ (Reverse hidden state dim: $h$). We can compute the forward hidden state and reverse hidden state separately:\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "&\\overrightarrow{\\boldsymbol{H}}_{t}=\\phi\\left(\\boldsymbol{X}_{t} \\boldsymbol{W}_{x h}^{(f)}+\\overrightarrow{\\boldsymbol{H}}_{t-1} \\boldsymbol{W}_{h h}^{(f)}+\\boldsymbol{b}_{h}^{(f)}\\right)\\\\\n",
    "&\\overleftarrow{\\boldsymbol{H}}_{t}=\\phi\\left(\\boldsymbol{X}_{t} \\boldsymbol{W}_{x h}^{(b)}+\\overleftarrow{\\boldsymbol{H}}_{t+1} \\boldsymbol{W}_{h h}^{(b)}+\\boldsymbol{b}_{h}^{(b)}\\right)\n",
    "\\end{aligned} $$\n",
    "\n",
    "\n",
    "Where, weight $\\boldsymbol{W}_{x h}^{(f)} \\in \\mathbb{R}^{d \\times h},  \\boldsymbol{W}_{h h}^{(f)} \\in \\mathbb{R}^{h \\times h},  \\boldsymbol{W}_{x h}^{(b)} \\in \\mathbb{R}^{d \\times h},  \\boldsymbol{W}_{h h}^{(b)} \\in \\mathbb{R}^{h \\times h}$ and bias  $\\boldsymbol{b}_{h}^{(f)} \\in \\mathbb{R}^{1 \\times h},  \\boldsymbol{b}_{h}^{(b)} \\in \\mathbb{R}^{1 \\times h}$ are params，$\\phi$ is the activation function for hidden layer.\n",
    "\n",
    "\n",
    "Then we concatenate the hidden states of two directions $\\overrightarrow{\\boldsymbol{H}}_{t}$ and  $\\overleftarrow{\\boldsymbol{H}}_{t}$ to get the hidden state $\\boldsymbol{H}_{t} \\in \\mathbb{R}^{n \\times 2 h}$, and feed it to output layer. The output layer calculates $\\boldsymbol{O}_{t} \\in \\mathbb{R}^{n \\times q}$（output dim: $q$）：\n",
    "\n",
    "\n",
    "$$ \\boldsymbol{O}_{t}=\\boldsymbol{H}_{t} \\boldsymbol{W}_{h q}+\\boldsymbol{b}_{q} $$\n",
    "\n",
    "\n",
    "Where, weight $\\boldsymbol{W}_{h q} \\in \\mathbb{R}^{2 h \\times q}$ and bias $\\boldsymbol{b}_{q} \\in \\mathbb{R}^{1 \\times q}$ are params for output layer. The hidden units dim can be different in different directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B74362BDF38A4BE29C773210FF836D71",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Luckily, we don't have to implement all from scratch, instead we can easily use built-in modules [`torch.nn.RNN`](https://pytorch.org/docs/stable/nn.html?highlight=rnn#torch.nn.RNN) or [`torch.nn.LSTM`](https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM) to build a bi-RNN model. (Yay! Truth is PyTorch made it a breeze!)\n",
    "\n",
    "Below I will show an example using [`torch.nn.LSTM`](https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM) to build the model for our sentiment analysis task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "graffitiCellId": "id_put7k6i",
    "id": "3F85195C090D49B8A78A951C4CD7076B",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab, embed_size, num_hiddens, num_layers):\n",
    "        '''\n",
    "        @params:\n",
    "            vocab: vocab created on the dataset\n",
    "            embed_size: embedding dim size\n",
    "            num_hiddens: hidden state dim\n",
    "            num_layers: num of hidden layers\n",
    "        '''\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size) # word embedding layer: get word vector from idx\n",
    "        \n",
    "        # encoder-decoder framework\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, \n",
    "                                hidden_size=num_hiddens, \n",
    "                                num_layers=num_layers,\n",
    "                                bidirectional=True) # set bidirectional to True\n",
    "        self.decoder = nn.Linear(4*num_hiddens, 2) # first and last timestep hidden state is input for FC dense layer\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        @params:\n",
    "            inputs: idx sequence of tokens, shape is (batch_size, seq_len) int tensor\n",
    "        @return:\n",
    "            outs: prediction of text sentiment, shape is (batch_size, 2) int tensor\n",
    "        '''\n",
    "        # transpose input as LSTM needs to have (seq_len) at 1st-dim\n",
    "        embeddings = self.embedding(inputs.permute(1, 0)) # (seq_len, batch_size, d)\n",
    "        # rnn.LSTM returns outputs, (hidden state, cell)\n",
    "        outputs, _ = self.encoder(embeddings) # (seq_len, batch_size, 2*h)\n",
    "        encoding = torch.cat((outputs[0], outputs[-1]), -1) # (batch_size, 4*h)\n",
    "        outs = self.decoder(encoding) # (batch_size, 2)\n",
    "        return outs\n",
    "\n",
    "embed_size, num_hiddens, num_layers = 100, 100, 2\n",
    "net = BiRNN(vocab, embed_size, num_hiddens, num_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_ksnuxvt",
    "id": "331B28609E2F4FCD81A30F5E665DB7EF",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- Load pre-trained word vectors\n",
    "\n",
    "Since the vocab and idx token of the pre-trained word vectors are not the same as the dataset we use, the pre-trained word vector needs to be loaded according to the current order of the vocab and idx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "graffitiCellId": "id_1x32tei",
    "id": "E1E904AB724240589BAF01DA77485092",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21202 oov words.\n"
     ]
    }
   ],
   "source": [
    "cache_dir = \"/home/kesci/input/GloVe6B5429\"\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=cache_dir) # 100dim is good enough\n",
    "#glove_vocab = Vocab.GloVe(name='6B', dim=300, cache=cache_dir) \n",
    "\n",
    "def load_pretrained_embedding(words, pretrained_vocab):\n",
    "    '''\n",
    "    @params:\n",
    "        words: list of word vectors to be loaded，as itos dictionary type\n",
    "        pretrained_vocab: pre-trained word vectors\n",
    "    @return:\n",
    "        embed: word vector loaded\n",
    "    '''\n",
    "    embed = torch.zeros(len(words), pretrained_vocab.vectors[0].shape[0]) # initialize to 0\n",
    "    oov_count = 0 # out of vocabulary\n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            idx = pretrained_vocab.stoi[word]\n",
    "            embed[i, :] = pretrained_vocab.vectors[idx]\n",
    "        except KeyError:\n",
    "            oov_count += 1\n",
    "    if oov_count > 0:\n",
    "        print(\"There are %d oov words.\" % oov_count)\n",
    "    return embed\n",
    "\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.embedding.weight.requires_grad = False # load pre-trained, no need to update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_rfun1jp",
    "id": "6C1065F141F041D68C843ECD13DB5193",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Model Training\n",
    "\n",
    "Define `train` and `evaluate_accuracy` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_jv4ye1d",
    "id": "6E7F2873372E42F0AD93F544A6DEEBDC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████▉| 399629/400000 [01:05<00:00, 7731.61it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        device = list(net.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval()\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train()\n",
    "            else:\n",
    "                if('is_training' in net.__code__.co_varnames):\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    \n",
    "    return acc_sum / n\n",
    "\n",
    "def train(train_iter, test_iter, net, loss, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    batch_count = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y) # calculate loss\n",
    "            optimizer.zero_grad() # reset grad to zero\n",
    "            l.backward() # backprop\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        \n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_jt55knm",
    "id": "3E29E40F14214A51B947A99BACBA7094",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "*Note: Since the params of the embedding layer do not need to be updated during the training, so we use the `filter` function and the`lambda` expression to filter out some parts of params that do not need to update.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "graffitiCellId": "id_qx54klj",
    "id": "AB49B88221294D6283A876AFA0A6700C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.2468, train acc 0.902, test acc 0.838, time 115.5 sec\n",
      "epoch 2, loss 0.1083, train acc 0.914, test acc 0.846, time 115.5 sec\n",
      "epoch 3, loss 0.0608, train acc 0.932, test acc 0.852, time 114.5 sec\n",
      "epoch 4, loss 0.0424, train acc 0.934, test acc 0.844, time 114.6 sec\n",
      "epoch 5, loss 0.0319, train acc 0.940, test acc 0.842, time 115.3 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 5\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_mxbji9v",
    "id": "E92D6D9EC8D84D998AFF2BC517515378",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "graffitiCellId": "id_rtedxzv",
    "id": "61A4F01E8A0C434CB6A193D540C58366",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sentiment(net, vocab, sentence):\n",
    "    '''\n",
    "    @params：\n",
    "        net: trained model\n",
    "        vocab: vocab on the dataset，mapping token to idx\n",
    "        sentence: text in word tokens seq\n",
    "    @return: pred outcome: positive for postive emotions，negative else\n",
    "    '''\n",
    "    device = list(net.parameters())[0].device # load the device location\n",
    "    sentence = torch.tensor([vocab.stoi[word] for word in sentence], device=device)\n",
    "    label = torch.argmax(net(sentence.view((1, -1))), dim=1)\n",
    "    return 'positive' if label.item() == 1 else 'negative'\n",
    "\n",
    "predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'great'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "graffitiCellId": "id_ci26bbu",
    "id": "F1AF9815A91C45C4B87B5641F632C949",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8C6640EA667C482C98B069E037C2B057",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- Summary\n",
    "\n",
    "Text classification transforms a sequence of text of indefinite length into a category of text. This is a downstream application of word embedding.\n",
    "\n",
    "We can apply pre-trained word vectors and recurrent neural networks to classify the emotions in a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69C53E3038C14C6C8E6F50107816AFF9",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
